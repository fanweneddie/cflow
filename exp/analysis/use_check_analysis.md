# Effect of field-use check at sink method

[toc]

I test the effect of field-use check at sink method and find 64 differences

Here I have two versions of `cflow`:

* version `type_check` that implements points-to analysis and checks the type of object that each variable references
* version `newest` that implements check of field use at sink method.

On both versions of `cflow`, I run command 

```
$ ./run.sh -a hadoop_common -sp
```

And I have found that, 64 sink taints in the output of `type_check` disappear in the output of `newest`.



Then, I revise the code in `newest` to print the type of all possible sink taints.

I find that for those 64 sink taints, 11 of them taints the field that must not be used in sink method and the remaining 53 of them taints the field that are unknown to be used in sink method(due to the lack of method body and limited search). Since we should reduce the number of false positive paths, I choose not to print those taints that may not be used in sink method.

PLUS: The sink taints are here:

```
11 sinks must not be used.
-- Sink $r3.<org.apache.hadoop.registry.server.dns.RegistryDNS$2: org.apache.hadoop.registry.server.dns.RegistryDNS this$0> in r5 = staticinvoke <org.apache.commons.io.FileUtils: java.util.Iterator iterateFiles(java.io.File,org.apache.commons.io.filefilter.IOFileFilter,org.apache.commons.io.filefilter.IOFileFilter)>($r2, $r3, null) in method <org.apache.hadoop.registry.server.dns.RegistryDNS: void initializeZonesFromFiles(org.apache.hadoop.conf.Configuration)> along:
-- Sink r0.<org.apache.hadoop.crypto.key.kms.ValueQueue$1: int val$watermarkValue> in specialinvoke r0.<com.google.common.cache.CacheLoader: void <init>()>() in method <org.apache.hadoop.crypto.key.kms.ValueQueue$1: void <init>(org.apache.hadoop.crypto.key.kms.ValueQueue,org.apache.hadoop.crypto.key.kms.ValueQueue$QueueRefiller,int)> along:
-- Sink r1.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem$Statistics statistics> in $r2 = staticinvoke <com.google.common.base.Preconditions: java.lang.Object checkNotNull(java.lang.Object)>(r1) in method <org.apache.hadoop.fs.Globber$GlobBuilder: void <init>(org.apache.hadoop.fs.FileSystem)> along:
-- Sink r1.<org.apache.hadoop.fs.FileSystem: org.apache.hadoop.fs.FileSystem$Cache$Key key> in $r2 = staticinvoke <com.google.common.base.Preconditions: java.lang.Object checkNotNull(java.lang.Object)>(r1) in method <org.apache.hadoop.fs.Globber$GlobBuilder: void <init>(org.apache.hadoop.fs.FileSystem)> along:
-- Sink r0.<org.apache.hadoop.crypto.key.kms.ValueQueue$1: org.apache.hadoop.crypto.key.kms.ValueQueue$QueueRefiller val$refiller> in specialinvoke r0.<com.google.common.cache.CacheLoader: void <init>()>() in method <org.apache.hadoop.crypto.key.kms.ValueQueue$1: void <init>(org.apache.hadoop.crypto.key.kms.ValueQueue,org.apache.hadoop.crypto.key.kms.ValueQueue$QueueRefiller,int)> along:
-- Sink r0.<org.apache.hadoop.security.Groups$GroupCacheLoader: org.apache.hadoop.security.Groups this$0> in specialinvoke r0.<com.google.common.cache.CacheLoader: void <init>()>() in method <org.apache.hadoop.security.Groups$GroupCacheLoader: void <init>(org.apache.hadoop.security.Groups)> along:
-- Sink $r7.<org.apache.hadoop.ha.HealthMonitor$MonitorDaemon$1: org.apache.hadoop.ha.HealthMonitor$MonitorDaemon this$1> in virtualinvoke r0.<org.apache.hadoop.ha.HealthMonitor$MonitorDaemon: void setUncaughtExceptionHandler(java.lang.Thread$UncaughtExceptionHandler)>($r7) in method <org.apache.hadoop.ha.HealthMonitor$MonitorDaemon: void <init>(org.apache.hadoop.ha.HealthMonitor)> along:
-- Sink r0.<org.apache.hadoop.crypto.key.kms.ValueQueue$1: org.apache.hadoop.crypto.key.kms.ValueQueue this$0> in specialinvoke r0.<com.google.common.cache.CacheLoader: void <init>()>() in method <org.apache.hadoop.crypto.key.kms.ValueQueue$1: void <init>(org.apache.hadoop.crypto.key.kms.ValueQueue,org.apache.hadoop.crypto.key.kms.ValueQueue$QueueRefiller,int)> along:
-- Sink r1.<org.apache.hadoop.fs.FileSystem: boolean resolveSymlinks> in $r2 = staticinvoke <com.google.common.base.Preconditions: java.lang.Object checkNotNull(java.lang.Object)>(r1) in method <org.apache.hadoop.fs.Globber$GlobBuilder: void <init>(org.apache.hadoop.fs.FileSystem)> along:
-- Sink $r7.<org.apache.hadoop.ha.HealthMonitor$MonitorDaemon$1: org.apache.hadoop.ha.HealthMonitor val$this$0> in virtualinvoke r0.<org.apache.hadoop.ha.HealthMonitor$MonitorDaemon: void setUncaughtExceptionHandler(java.lang.Thread$UncaughtExceptionHandler)>($r7) in method <org.apache.hadoop.ha.HealthMonitor$MonitorDaemon: void <init>(org.apache.hadoop.ha.HealthMonitor)> along:
-- Sink r0.<org.apache.hadoop.util.Shell$1: org.apache.hadoop.util.Shell this$0> in $z0 = virtualinvoke r0.<org.apache.hadoop.util.Shell$1: boolean isInterrupted()>() in method <org.apache.hadoop.util.Shell$1: void run()> along:
-----------------------------------------------------------
53 sinks are unknown to be used.
-- Sink r69.<org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext$Context: org.apache.hadoop.fs.FileSystem localFS> in virtualinvoke $r24.<java.util.concurrent.atomic.AtomicReference: void set(java.lang.Object)>(r69) in method <org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext: org.apache.hadoop.fs.LocalDirAllocator$AllocatorPerContext$Context confChanged(org.apache.hadoop.conf.Configuration)> along:
-- Sink r0.<org.apache.hadoop.security.UserGroupInformation$HadoopLoginContext: org.apache.hadoop.security.UserGroupInformation$HadoopConfiguration conf> in specialinvoke r0.<javax.security.auth.login.LoginContext: void login()>() in method <org.apache.hadoop.security.UserGroupInformation$HadoopLoginContext: void login()> along:
-- Sink $r3.<org.apache.hadoop.registry.server.dns.RegistryDNS$5: org.apache.hadoop.registry.server.dns.RegistryDNS this$0> in interfaceinvoke $r4.<java.util.concurrent.ExecutorService: java.util.concurrent.Future submit(java.util.concurrent.Callable)>($r3) in method <org.apache.hadoop.registry.server.dns.RegistryDNS: void addNIOUDP(java.net.InetAddress,int)> along:
-- Sink r0.<org.apache.hadoop.ipc.Server$Listener: boolean reuseAddr> in virtualinvoke r0.<org.apache.hadoop.ipc.Server$Listener: void setDaemon(boolean)>(1) in method <org.apache.hadoop.ipc.Server$Listener: void <init>(org.apache.hadoop.ipc.Server,int)> along:
-- Sink $r3.<org.apache.hadoop.fs.CachingGetSpaceUsed$RefreshThread: org.apache.hadoop.fs.CachingGetSpaceUsed spaceUsed> in specialinvoke $r2.<java.lang.Thread: void <init>(java.lang.Runnable,java.lang.String)>($r3, $r8) in method <org.apache.hadoop.fs.CachingGetSpaceUsed: void initRefeshThread(boolean)> along:
-- Sink r0.<org.apache.hadoop.ipc.Server$Responder: org.apache.hadoop.ipc.Server this$0> in specialinvoke r0.<java.lang.Thread: void <init>()>() in method <org.apache.hadoop.ipc.Server$Responder: void <init>(org.apache.hadoop.ipc.Server)> along:
-- Sink r24.<org.apache.hadoop.util.Shell$1: org.apache.hadoop.util.Shell this$0> in virtualinvoke r24.<java.lang.Thread: void interrupt()>() in method <org.apache.hadoop.util.Shell: void runCommand()> along:
-- Sink r2.<org.apache.hadoop.crypto.key.kms.server.KMS$1: org.apache.hadoop.crypto.key.KeyProvider$Options val$options> in $r4 = staticinvoke <javax.security.auth.Subject: java.lang.Object doAs(javax.security.auth.Subject,java.security.PrivilegedExceptionAction)>($r3, r2) in method <org.apache.hadoop.security.UserGroupInformation: java.lang.Object doAs(java.security.PrivilegedExceptionAction)> along:
-- Sink r0.<org.apache.hadoop.ha.HealthMonitor$MonitorDaemon: org.apache.hadoop.ha.HealthMonitor this$0> in virtualinvoke r0.<org.apache.hadoop.ha.HealthMonitor$MonitorDaemon: void setUncaughtExceptionHandler(java.lang.Thread$UncaughtExceptionHandler)>($r7) in method <org.apache.hadoop.ha.HealthMonitor$MonitorDaemon: void <init>(org.apache.hadoop.ha.HealthMonitor)> along:
-- Sink r7.<org.apache.hadoop.security.UserGroupInformation$TicketCacheRenewalRunnable: java.lang.String kinitCmd> in interfaceinvoke $r8.<java.util.concurrent.ExecutorService: java.util.concurrent.Future submit(java.lang.Runnable)>(r7) in method <org.apache.hadoop.security.UserGroupInformation: void executeAutoRenewalTask(java.lang.String,org.apache.hadoop.security.UserGroupInformation$AutoRenewalForUserCredsRunnable)> along:
-- Sink r0.<org.apache.hadoop.util.Shell$1: org.apache.hadoop.util.Shell this$0> in virtualinvoke r0.<java.lang.Thread: void interrupt()>() in method <org.apache.hadoop.util.Shell: void joinThread(java.lang.Thread)> along:
-- Sink r0.<org.apache.hadoop.ipc.Server$Listener: org.apache.hadoop.ipc.Server this$0> in specialinvoke r0.<java.lang.Thread: void <init>()>() in method <org.apache.hadoop.ipc.Server$Listener: void <init>(org.apache.hadoop.ipc.Server,int)> along:
-- Sink r6.<org.apache.hadoop.ipc.DecayRpcScheduler$MetricsProxy: java.lang.ref.WeakReference delegate> in interfaceinvoke r0.<javax.management.MBeanServer: javax.management.ObjectInstance registerMBean(java.lang.Object,javax.management.ObjectName)>(r6, r5) in method <org.apache.hadoop.metrics2.util.MBeans: javax.management.ObjectName register(java.lang.String,java.lang.String,java.util.Map,java.lang.Object)> along:
-- Sink r1.<org.apache.hadoop.fs.sftp.SFTPInputStream: java.io.InputStream wrappedStream> in specialinvoke r0.<java.io.DataInputStream: void <init>(java.io.InputStream)>(r1) in method <org.apache.hadoop.fs.FSDataInputStream: void <init>(java.io.InputStream)> along:
-- Sink $r38.<org.apache.hadoop.metrics2.lib.MutableQuantiles$RolloverSample: org.apache.hadoop.metrics2.lib.MutableQuantiles parent> in $r41 = interfaceinvoke $r39.<java.util.concurrent.ScheduledExecutorService: java.util.concurrent.ScheduledFuture scheduleWithFixedDelay(java.lang.Runnable,long,long,java.util.concurrent.TimeUnit)>($r38, $l4, $l3, $r40) in method <org.apache.hadoop.metrics2.lib.MutableQuantiles: void <init>(java.lang.String,java.lang.String,java.lang.String,java.lang.String,int)> along:
-- Sink r0.<org.apache.hadoop.ipc.Server$Listener: boolean reuseAddr> in virtualinvoke r0.<org.apache.hadoop.ipc.Server$Listener: void setName(java.lang.String)>($r38) in method <org.apache.hadoop.ipc.Server$Listener: void <init>(org.apache.hadoop.ipc.Server,int)> along:
-- Sink r2.<org.apache.hadoop.fs.FileContext$2: java.net.URI val$uri> in $r4 = staticinvoke <javax.security.auth.Subject: java.lang.Object doAs(javax.security.auth.Subject,java.security.PrivilegedExceptionAction)>($r3, r2) in method <org.apache.hadoop.security.UserGroupInformation: java.lang.Object doAs(java.security.PrivilegedExceptionAction)> along:
-- Sink r0.<org.apache.hadoop.ipc.Client$Connection: int maxResponseLength> in virtualinvoke r0.<org.apache.hadoop.ipc.Client$Connection: void setDaemon(boolean)>(1) in method <org.apache.hadoop.ipc.Client$Connection: void <init>(org.apache.hadoop.ipc.Client,org.apache.hadoop.ipc.Client$ConnectionId,int,java.util.function.Consumer)> along:
-- Sink r0.<org.apache.hadoop.ipc.Server$Responder: org.apache.hadoop.ipc.Server this$0> in virtualinvoke r0.<org.apache.hadoop.ipc.Server$Responder: void setName(java.lang.String)>("IPC Server Responder") in method <org.apache.hadoop.ipc.Server$Responder: void <init>(org.apache.hadoop.ipc.Server)> along:
-- Sink $r18.<org.apache.hadoop.security.Groups$GroupCacheLoader: org.apache.hadoop.security.Groups this$0> in $r19 = virtualinvoke $r17.<com.google.common.cache.CacheBuilder: com.google.common.cache.LoadingCache build(com.google.common.cache.CacheLoader)>($r18) in method <org.apache.hadoop.security.Groups: void <init>(org.apache.hadoop.conf.Configuration,org.apache.hadoop.util.Timer)> along:
-- Sink r11.<org.apache.hadoop.security.ssl.SSLFactory: boolean requireClientCert> in specialinvoke $r13.<org.apache.hadoop.security.authentication.client.AuthenticatedURL: void <init>(org.apache.hadoop.security.authentication.client.Authenticator,org.apache.hadoop.security.authentication.client.ConnectionConfigurator)>($r14, r11) in method <org.apache.hadoop.log.LogLevel$CLI: java.net.URLConnection connect(java.net.URL)> along:
-- Sink r24.<org.apache.hadoop.util.Shell$1: org.apache.hadoop.util.Shell this$0> in virtualinvoke r24.<java.lang.Thread: void interrupt()>() in method <org.apache.hadoop.util.Shell: void runCommand()> along:
-- Sink r3.<org.apache.hadoop.registry.client.impl.zk.CuratorService$1: org.apache.hadoop.registry.client.impl.zk.PathListener val$listener> in interfaceinvoke $r5.<org.apache.curator.framework.listen.Listenable: void addListener(java.lang.Object)>(r3) in method <org.apache.hadoop.registry.client.impl.zk.CuratorService: org.apache.hadoop.registry.client.impl.zk.ListenerHandle registerPathListener(org.apache.hadoop.registry.client.impl.zk.PathListener)> along:
-- Sink r0.<org.apache.hadoop.ipc.Server$Listener: org.apache.hadoop.ipc.Server this$0> in virtualinvoke r0.<org.apache.hadoop.ipc.Server$Listener: void setDaemon(boolean)>(1) in method <org.apache.hadoop.ipc.Server$Listener: void <init>(org.apache.hadoop.ipc.Server,int)> along:
-- Sink r1.<org.apache.hadoop.crypto.CryptoInputStream: int bufferSize> in specialinvoke r0.<java.io.DataInputStream: void <init>(java.io.InputStream)>(r1) in method <org.apache.hadoop.fs.FSDataInputStream: void <init>(java.io.InputStream)> along:
-- Sink r11.<org.apache.hadoop.security.ssl.SSLFactory: java.util.List excludeCiphers> in specialinvoke $r13.<org.apache.hadoop.security.authentication.client.AuthenticatedURL: void <init>(org.apache.hadoop.security.authentication.client.Authenticator,org.apache.hadoop.security.authentication.client.ConnectionConfigurator)>($r14, r11) in method <org.apache.hadoop.log.LogLevel$CLI: java.net.URLConnection connect(java.net.URL)> along:
-- Sink r0.<org.apache.hadoop.util.Shell$1: org.apache.hadoop.util.Shell this$0> in specialinvoke r0.<java.lang.Thread: void <init>()>() in method <org.apache.hadoop.util.Shell$1: void <init>(org.apache.hadoop.util.Shell,java.io.BufferedReader,java.lang.StringBuffer)> along:
-- Sink r0.<org.apache.hadoop.ipc.Server$Listener: int backlogLength> in virtualinvoke r0.<org.apache.hadoop.ipc.Server$Listener: void setName(java.lang.String)>($r38) in method <org.apache.hadoop.ipc.Server$Listener: void <init>(org.apache.hadoop.ipc.Server,int)> along:
-- Sink $r9.<org.apache.hadoop.crypto.key.kms.ValueQueue$1: org.apache.hadoop.crypto.key.kms.ValueQueue$QueueRefiller val$refiller> in $r10 = virtualinvoke $r8.<com.google.common.cache.CacheBuilder: com.google.common.cache.LoadingCache build(com.google.common.cache.CacheLoader)>($r9) in method <org.apache.hadoop.crypto.key.kms.ValueQueue: void <init>(int,float,long,int,org.apache.hadoop.crypto.key.kms.ValueQueue$SyncGenerationPolicy,org.apache.hadoop.crypto.key.kms.ValueQueue$QueueRefiller)> along:
-- Sink r21.<org.apache.hadoop.security.UserGroupInformation$HadoopLoginContext: org.apache.hadoop.security.UserGroupInformation$HadoopConfiguration conf> in $r23 = virtualinvoke r21.<org.apache.hadoop.security.UserGroupInformation$HadoopLoginContext: javax.security.auth.Subject getSubject()>() in method <org.apache.hadoop.security.UserGroupInformation: org.apache.hadoop.security.UserGroupInformation doSubjectLogin(javax.security.auth.Subject,org.apache.hadoop.security.UserGroupInformation$LoginParams)> along:
-- Sink r1.<org.apache.hadoop.crypto.CryptoOutputStream: int bufferSize> in specialinvoke r0.<java.io.FilterOutputStream: void <init>(java.io.OutputStream)>(r1) in method <org.apache.hadoop.fs.FSDataOutputStream$PositionCache: void <init>(java.io.OutputStream,org.apache.hadoop.fs.FileSystem$Statistics,long)> along:
-- Sink r11.<org.apache.hadoop.security.ssl.SSLFactory: java.lang.String[] enabledProtocols> in specialinvoke $r13.<org.apache.hadoop.security.authentication.client.AuthenticatedURL: void <init>(org.apache.hadoop.security.authentication.client.Authenticator,org.apache.hadoop.security.authentication.client.ConnectionConfigurator)>($r14, r11) in method <org.apache.hadoop.log.LogLevel$CLI: java.net.URLConnection connect(java.net.URL)> along:
-- Sink $r9.<org.apache.hadoop.crypto.key.kms.ValueQueue$1: org.apache.hadoop.crypto.key.kms.ValueQueue this$0> in $r10 = virtualinvoke $r8.<com.google.common.cache.CacheBuilder: com.google.common.cache.LoadingCache build(com.google.common.cache.CacheLoader)>($r9) in method <org.apache.hadoop.crypto.key.kms.ValueQueue: void <init>(int,float,long,int,org.apache.hadoop.crypto.key.kms.ValueQueue$SyncGenerationPolicy,org.apache.hadoop.crypto.key.kms.ValueQueue$QueueRefiller)> along:
-- Sink r0.<org.apache.hadoop.util.Shell$1: org.apache.hadoop.util.Shell this$0> in virtualinvoke r0.<java.lang.Thread: void join()>() in method <org.apache.hadoop.util.Shell: void joinThread(java.lang.Thread)> along:
-- Sink r0.<org.apache.hadoop.ipc.Server$Listener$Reader: org.apache.hadoop.ipc.Server$Listener this$1> in specialinvoke r0.<java.lang.Thread: void <init>(java.lang.String)>(r2) in method <org.apache.hadoop.ipc.Server$Listener$Reader: void <init>(org.apache.hadoop.ipc.Server$Listener,java.lang.String)> along:
-- Sink $r3.<org.apache.hadoop.registry.server.dns.RegistryDNS$5: int val$port> in interfaceinvoke $r4.<java.util.concurrent.ExecutorService: java.util.concurrent.Future submit(java.util.concurrent.Callable)>($r3) in method <org.apache.hadoop.registry.server.dns.RegistryDNS: void addNIOUDP(java.net.InetAddress,int)> along:
-- Sink r3.<org.apache.hadoop.security.UserGroupInformation$HadoopConfiguration: org.apache.hadoop.security.UserGroupInformation$LoginParams params> in specialinvoke r0.<javax.security.auth.login.LoginContext: void <init>(java.lang.String,javax.security.auth.Subject,javax.security.auth.callback.CallbackHandler,javax.security.auth.login.Configuration)>(r1, r2, null, r3) in method <org.apache.hadoop.security.UserGroupInformation$HadoopLoginContext: void <init>(java.lang.String,javax.security.auth.Subject,org.apache.hadoop.security.UserGroupInformation$HadoopConfiguration)> along:
-- Sink r0.<org.apache.hadoop.fs.sftp.SFTPFileSystem$2: com.jcraft.jsch.ChannelSftp val$client> in specialinvoke r0.<java.io.DataOutputStream: void <init>(java.io.OutputStream)>($r1) in method <org.apache.hadoop.fs.FSDataOutputStream: void <init>(java.io.OutputStream,org.apache.hadoop.fs.FileSystem$Statistics,long)> along:
-- Sink r0.<org.apache.hadoop.fs.sftp.SFTPFileSystem$1: com.jcraft.jsch.ChannelSftp val$channel> in specialinvoke r0.<java.io.DataInputStream: void <init>(java.io.InputStream)>(r1) in method <org.apache.hadoop.fs.FSDataInputStream: void <init>(java.io.InputStream)> along:
-- Sink r0.<org.apache.hadoop.ha.HealthMonitor$MonitorDaemon: org.apache.hadoop.ha.HealthMonitor this$0> in virtualinvoke r0.<org.apache.hadoop.util.Daemon: void setDaemon(boolean)>(1) in method <org.apache.hadoop.util.Daemon: void <init>()> along:
-- Sink r0.<org.apache.hadoop.ipc.Server$Listener: org.apache.hadoop.ipc.Server this$0> in virtualinvoke r0.<org.apache.hadoop.ipc.Server$Listener: void setName(java.lang.String)>($r38) in method <org.apache.hadoop.ipc.Server$Listener: void <init>(org.apache.hadoop.ipc.Server,int)> along:
-- Sink $r3.<org.apache.hadoop.registry.server.dns.RegistryDNS$4: org.apache.hadoop.registry.server.dns.RegistryDNS this$0> in interfaceinvoke $r4.<java.util.concurrent.ExecutorService: java.util.concurrent.Future submit(java.util.concurrent.Callable)>($r3) in method <org.apache.hadoop.registry.server.dns.RegistryDNS: void addNIOTCP(java.net.InetAddress,int)> along:
-- Sink r0.<org.apache.hadoop.security.UserGroupInformation$HadoopLoginContext: org.apache.hadoop.security.UserGroupInformation$HadoopConfiguration conf> in r1 = virtualinvoke r0.<org.apache.hadoop.security.UserGroupInformation$HadoopLoginContext: javax.security.auth.Subject getSubject()>() in method <org.apache.hadoop.security.UserGroupInformation$HadoopLoginContext: java.lang.Object getSubjectLock()> along:
-- Sink $r3.<org.apache.hadoop.registry.server.dns.RegistryDNS$4: int val$port> in interfaceinvoke $r4.<java.util.concurrent.ExecutorService: java.util.concurrent.Future submit(java.util.concurrent.Callable)>($r3) in method <org.apache.hadoop.registry.server.dns.RegistryDNS: void addNIOTCP(java.net.InetAddress,int)> along:
-- Sink r1.<org.apache.hadoop.util.JvmPauseMonitor$Monitor: org.apache.hadoop.util.JvmPauseMonitor this$0> in specialinvoke r0.<java.lang.Thread: void <init>(java.lang.Runnable)>(r1) in method <org.apache.hadoop.util.Daemon: void <init>(java.lang.Runnable)> along:
-- Sink r0.<org.apache.hadoop.ipc.Client$Connection: int maxResponseLength> in virtualinvoke r0.<org.apache.hadoop.ipc.Client$Connection: void setName(java.lang.String)>($r23) in method <org.apache.hadoop.ipc.Client$Connection: void <init>(org.apache.hadoop.ipc.Client,org.apache.hadoop.ipc.Client$ConnectionId,int,java.util.function.Consumer)> along:
-- Sink r0.<org.apache.hadoop.util.Daemon: java.lang.Runnable runnable> in virtualinvoke r0.<org.apache.hadoop.util.Daemon: void setName(java.lang.String)>($r2) in method <org.apache.hadoop.util.Daemon: void <init>(java.lang.Runnable)> along:
-- Sink r0.<org.apache.hadoop.util.Shell$1: org.apache.hadoop.util.Shell this$0> in $z1 = virtualinvoke r0.<java.lang.Thread: boolean isAlive()>() in method <org.apache.hadoop.util.Shell: void joinThread(java.lang.Thread)> along:
-- Sink r0.<org.apache.hadoop.ipc.Server$Listener: int backlogLength> in virtualinvoke r0.<org.apache.hadoop.ipc.Server$Listener: void setDaemon(boolean)>(1) in method <org.apache.hadoop.ipc.Server$Listener: void <init>(org.apache.hadoop.ipc.Server,int)> along:
-- Sink r0.<org.apache.hadoop.ha.HealthMonitor$MonitorDaemon: org.apache.hadoop.ha.HealthMonitor this$0> in specialinvoke r0.<java.lang.Thread: void <init>()>() in method <org.apache.hadoop.util.Daemon: void <init>()> along:
-- Sink $r9.<org.apache.hadoop.crypto.key.kms.ValueQueue$1: int val$watermarkValue> in $r10 = virtualinvoke $r8.<com.google.common.cache.CacheBuilder: com.google.common.cache.LoadingCache build(com.google.common.cache.CacheLoader)>($r9) in method <org.apache.hadoop.crypto.key.kms.ValueQueue: void <init>(int,float,long,int,org.apache.hadoop.crypto.key.kms.ValueQueue$SyncGenerationPolicy,org.apache.hadoop.crypto.key.kms.ValueQueue$QueueRefiller)> along:
-- Sink r0.<org.apache.hadoop.ha.HealthMonitor$MonitorDaemon: org.apache.hadoop.ha.HealthMonitor this$0> in virtualinvoke r0.<org.apache.hadoop.ha.HealthMonitor$MonitorDaemon: void setName(java.lang.String)>($r6) in method <org.apache.hadoop.ha.HealthMonitor$MonitorDaemon: void <init>(org.apache.hadoop.ha.HealthMonitor)> along:
-- Sink r0.<org.apache.hadoop.ipc.Server$Responder: org.apache.hadoop.ipc.Server this$0> in virtualinvoke r0.<org.apache.hadoop.ipc.Server$Responder: void setDaemon(boolean)>(1) in method <org.apache.hadoop.ipc.Server$Responder: void <init>(org.apache.hadoop.ipc.Server)> along:
-----------------------------------------------------------
0 sinks may be used.
-----------------------------------------------------------
```

